{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The File for generating HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wand.image import Image as wi\n",
    "import os; from io import BytesIO; import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from tesserocr import PyTessBaseAPI, RIL, iterate_level, PT, OEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../datafiles/dfile.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytestapi_path = \"C:\\\\Tesseract\\\\Tesseract-OCR-v4\\\\tessdata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdf to Images List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf2ImagesList(filepath):\n",
    "    pdf = wi(filename = filepath, resolution=800, background = 'white')\n",
    "    numPages = len(pdf.sequence)   #should be a class prop\n",
    "    pdfImages = pdf.convert(\"jpeg\")\n",
    "    \n",
    "    pageImages = []   #should be a class prop\n",
    "    for img in pdfImages.sequence:\n",
    "        page = wi(img)\n",
    "        PIL_img = Image.open(BytesIO(page.make_blob('jpeg')))\n",
    "        if(PIL_img.mode != 'RGB'):\n",
    "            pageImages.append(PIL_img.convert('RGB'))\n",
    "        else:\n",
    "            pageImages.append(PIL_img)\n",
    "    \n",
    "    return pageImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepageImages = pdf2ImagesList(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filepageImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise calculation [per page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_val_Image(imagePIL, NoiseThreshold_ppage): # NoiseThreshold_ppage is b/w 0 and 1\n",
    "    '''\n",
    "    Params:\n",
    "        imagePIL - PIL image object\n",
    "        NoiseThreshold_ppage - %age noise threshold for an image range [0, 1]\n",
    "        \n",
    "    Returns:\n",
    "        ratio of dark pixels and total pixels\n",
    "        boolean page acceptance result based on noise ratio\n",
    "        binary image with 0 representing noise pixels\n",
    "    '''\n",
    "    \n",
    "    BinaryThreshold = 195  ## threshold per pixel \n",
    "    \n",
    "    grayPIL = imagePIL.convert('L')\n",
    "    imageNUMPY = np.array(grayPIL, dtype='uint8')\n",
    "    \n",
    "    Tessstart = time.time()\n",
    "    \n",
    "    with PyTessBaseAPI(path = \"C:\\\\Tesseract\\\\Tesseract-OCR-v3\\\\tessdata\") as api:\n",
    "        api.SetImage(imagePIL)\n",
    "        api.Recognize()\n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.TEXTLINE\n",
    "        for r in iterate_level(ri, level):\n",
    "            x1, y1, x2, y2 = r.BoundingBox(level)\n",
    "            imageNUMPY[y1:y2, x1:x2] = 255\n",
    "    \n",
    "    bin_ = np.zeros(imageNUMPY.shape)\n",
    "    bin_ = np.where(imageNUMPY > BinaryThreshold, 1, 0)\n",
    "    \n",
    "    pixels_num = bin_.shape[0]*bin_.shape[1]\n",
    "    ratio = (pixels_num - bin_.sum())/pixels_num\n",
    "    \n",
    "    return ratio, ratio > NoiseThreshold_ppage, bin_ #returns the ratio, rejection result, binary_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_params_PDF(PDFImages, NoiseThreshold_ppage  = 0.50):\n",
    "    ''' IN-PROGRESS\n",
    "    PDFImages: r x c x ch x num where num is number of \n",
    "    '''\n",
    "    PAGESCOUNT = len(PDFImages)\n",
    "    pageNoiseFlag = [0]*PAGESCOUNT   #should be a class prop\n",
    "\n",
    "    FORstart = time.time()\n",
    "    \n",
    "    for i in range(0, len(PDFImages)):\n",
    "        #ITstart = time.time()\n",
    "        if(get_noise_val_Image(PDFImages[i], NoiseThreshold_ppage)[1]): #rejection means: page is noisy\n",
    "            pageNoiseFlag[i] = 1\n",
    "        #print(\"Iteration-Time taken\", time.time() - ITstart)\n",
    "    \n",
    "    print(\"FOR EndTime taken\", time.time() - FORstart)\n",
    "    \n",
    "    return   sum(pageNoiseFlag)/PAGESCOUNT, pageNoiseFlag #returns the %age of pages that are noisy [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EndTime taken 17.110139846801758\n"
     ]
    }
   ],
   "source": [
    "noiseratio, noise_bin = get_noise_params_PDF(filepageImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:\t 0.0 \t\tList:\t [0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio:\\t\", noiseratio, \"\\t\\tList:\\t\", noise_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR SCAN\n",
    "* Images to Text Conversion \n",
    "* Table Detection (Table detection does happens in the java code but doesn't go in the grain)\n",
    "     * TH , TR , TD\n",
    "* Background Detection\n",
    "    * Specific Line Background\n",
    "    * Word Level, Block Level & Line Level (Under Progress)\n",
    "    \n",
    "* Font Characterstics\n",
    "    * Font Density ( Tried to do in jar but was inefficent, insufficent and inaccurate)\n",
    "        * Bold \n",
    "        * Light\n",
    "    * Font Size\n",
    "* Hand Written Detection (ITS UNDER PROGRESS)\n",
    "    * HandWritten Model vs Digital Text Model\n",
    "    * Evaluation of Metrices\n",
    "    \n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_bg_detection(bbox, numBIN, NUMPYimage):\n",
    "    if bbox:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        colorbin = np.ones((numBIN, 3), dtype = 'int16') *-1\n",
    "\n",
    "        combs = np.where(NUMPYimage[y1:y2, x1:x2, 0] != -1) # Check if the image didn't had the -1 there\n",
    "        if (combs[0].size != 0): # check if the size is not zero \n",
    "            bin_i = 0\n",
    "            # Choose randomly bins (20 is the default set right now )\n",
    "            # To check the image or the bin or whatsoever \n",
    "            for i in np.random.choice(range(combs[0].shape[0]), numBIN):\n",
    "                x = combs[1][i]\n",
    "                y = combs[0][i]\n",
    "                colorbin[bin_i] = NUMPYimage[y1+y, x1+x, :]\n",
    "                bin_i += 1\n",
    "            # Historgram \n",
    "\n",
    "            hist = {}\n",
    "            for r, g, b in colorbin:\n",
    "                if not (r == -1):\n",
    "                    RGB = str(r)+\"_\"+str(g)+\"_\"+str(b)\n",
    "                    if RGB in list(hist.keys()):\n",
    "                        hist[RGB] += 1\n",
    "                    else:\n",
    "                        hist[RGB] = 1\n",
    "            if len(list(hist.keys())):\n",
    "                return list(hist.keys())[list(hist.values()).index(max(list(hist.values())))].split(\"_\") ## RGB value in list\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_row_tags(image):\n",
    "    image.show()\n",
    "    with PyTessBaseAPI(path=pytestapi_path) as api:\n",
    "        api.SetImage(image)\n",
    "        api.Recognize()\n",
    "        \n",
    "        #GET PARA TEXT\n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.BLOCK\n",
    "        \n",
    "        rows_bbox = []\n",
    "        for r in iterate_level(ri, level):\n",
    "            block_type = r.BlockType()\n",
    "            print(block_type)\n",
    "            if (block_type == PT.HORZ_LINE):\n",
    "                print(block_type)\n",
    "                tmp = {}\n",
    "                tmp['bbox'] = r.BoundingBox(level)\n",
    "                rows_bbox.append(tmp)\n",
    "        \n",
    "        #GET PARA TEXT\n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.WORD\n",
    "        \n",
    "        for r in iterate_level(ri, level):\n",
    "            \n",
    "            word = r.GetUTF8Text(level)\n",
    "            curr_bbox = r.BoundingBox(level)\n",
    "            print(curr_bbox, word) # This is printing the values ! !\n",
    "            print(\"HEY HEY HEY\",len(rows_bbox))\n",
    "            for i in range(len(rows_bbox)):\n",
    "                # Need to test whether hte Rows bbox is working or not ! \n",
    "                print(curr_bbox[1] <= rows_bbox[i]['bbox'][1])\n",
    "                if (curr_bbox[1] <= rows_bbox[i]['bbox'][1]):\n",
    "                    if 'text' not in list(rows_bbox[i].keys()):\n",
    "                        rows_bbox[i]['text'] = word\n",
    "                    else:\n",
    "                        rows_bbox[i]['text'] += \" \"+word\n",
    "                    break\n",
    "        print(rows_bbox)\n",
    "        if (len(rows_bbox) > 0):\n",
    "            table_text = \"<table>\\n<th>\\n\"+rows_bbox[0]['text']+'\\n</th>\\n'\n",
    "            for i in rows_bbox[1:]:\n",
    "                if ('text' in list(i.keys())):\n",
    "                    table_text += \"<tr>\\n\"+i['text']+'\\n</tr>\\n'\n",
    "            table_text += \"</table> /n \"\n",
    "            print(table_text)\n",
    "            return table_text\n",
    "    \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "yes\n",
      "1\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "(47, 182, 302, 248) Linear\n",
      "HEY HEY HEY 0\n",
      "(682, 180, 916, 261) faster,\n",
      "HEY HEY HEY 0\n",
      "(949, 180, 1134, 269) good\n",
      "HEY HEY HEY 0\n",
      "(1163, 180, 1275, 248) for\n",
      "HEY HEY HEY 0\n",
      "(1304, 180, 1515, 269) large,\n",
      "HEY HEY HEY 0\n",
      "(1548, 180, 1744, 248) fixed\n",
      "HEY HEY HEY 0\n",
      "(1988, 180, 2247, 248) unable\n",
      "HEY HEY HEY 0\n",
      "(2273, 190, 2347, 248) to\n",
      "HEY HEY HEY 0\n",
      "(2376, 180, 2530, 248) deal\n",
      "HEY HEY HEY 0\n",
      "(2562, 180, 2729, 248) with\n",
      "HEY HEY HEY 0\n",
      "(2755, 180, 3230, 269) non—linearly\n",
      "HEY HEY HEY 0\n",
      "(3258, 180, 3621, 268) separable\n",
      "HEY HEY HEY 0\n",
      "(3649, 180, 3826, 261) data,\n",
      "HEY HEY HEY 0\n",
      "(3936, 180, 4231, 269) [linearly\n",
      "HEY HEY HEY 0\n",
      "(4259, 180, 4620, 268) separable\n",
      "HEY HEY HEY 0\n",
      "(4651, 180, 4809, 248) data\n",
      "HEY HEY HEY 0\n",
      "(4836, 202, 4968, 269) e.g.\n",
      "HEY HEY HEY 0\n",
      "(5001, 190, 5143, 248) text\n",
      "HEY HEY HEY 0\n",
      "(41, 159, 980, 494) number\n",
      "HEY HEY HEY 0\n",
      "(1007, 291, 1088, 359) of\n",
      "HEY HEY HEY 0\n",
      "(1109, 291, 1435, 372) features,\n",
      "HEY HEY HEY 0\n",
      "(1467, 313, 1561, 359) no\n",
      "HEY HEY HEY 0\n",
      "(1990, 291, 2161, 359) does\n",
      "HEY HEY HEY 0\n",
      "(2193, 301, 2315, 359) not\n",
      "HEY HEY HEY 0\n",
      "(2341, 291, 2500, 359) take\n",
      "HEY HEY HEY 0\n",
      "(2528, 291, 3098, 359) feature—feature\n",
      "HEY HEY HEY 0\n",
      "(3123, 291, 3616, 379) relationships\n",
      "HEY HEY HEY 0\n",
      "(3936, 291, 4445, 359) classification\n",
      "HEY HEY HEY 0\n",
      "(680, 413, 1102, 491) parameters\n",
      "HEY HEY HEY 0\n",
      "(47, 520, 491, 609) Polynomial\n",
      "HEY HEY HEY 0\n",
      "(685, 520, 1075, 588) somewhat\n",
      "HEY HEY HEY 0\n",
      "(1104, 520, 1371, 588) similar\n",
      "HEY HEY HEY 0\n",
      "(1393, 530, 1466, 588) to\n",
      "HEY HEY HEY 0\n",
      "(1495, 520, 1715, 588) linear\n",
      "HEY HEY HEY 0\n",
      "(1741, 520, 2249, 607) where|degree\n",
      "HEY HEY HEY 0\n",
      "(2275, 530, 2666, 608) parameter\n",
      "HEY HEY HEY 0\n",
      "(2692, 520, 2909, 588) needs\n",
      "HEY HEY HEY 0\n",
      "(2938, 530, 3011, 588) to\n",
      "HEY HEY HEY 0\n",
      "(3038, 520, 3126, 588) be\n",
      "HEY HEY HEY 0\n",
      "(3157, 520, 3485, 601) selected,\n",
      "HEY HEY HEY 0\n",
      "(3517, 520, 3764, 609) higher\n",
      "HEY HEY HEY 0\n",
      "(0, 0, 5236, 2697) _\n",
      "HEY HEY HEY 0\n",
      "(3936, 520, 4198, 609) |(mostly\n",
      "HEY HEY HEY 0\n",
      "(4222, 520, 4401, 588) used\n",
      "HEY HEY HEY 0\n",
      "(4427, 520, 4502, 587) in\n",
      "HEY HEY HEY 0\n",
      "(4532, 520, 4790, 608) speech\n",
      "HEY HEY HEY 0\n",
      "(41, 499, 843, 836) data\n",
      "HEY HEY HEY 0\n",
      "(867, 631, 928, 699) is\n",
      "HEY HEY HEY 0\n",
      "(959, 631, 1122, 699) well\n",
      "HEY HEY HEY 0\n",
      "(1153, 631, 1532, 719) separable,\n",
      "HEY HEY HEY 0\n",
      "(1990, 631, 2247, 720) degree\n",
      "HEY HEY HEY 0\n",
      "(2274, 653, 2406, 699) can\n",
      "HEY HEY HEY 0\n",
      "(2437, 631, 2709, 712) overfit,\n",
      "HEY HEY HEY 0\n",
      "(2744, 631, 2998, 699) slower\n",
      "HEY HEY HEY 0\n",
      "(3023, 631, 3189, 699) than\n",
      "HEY HEY HEY 0\n",
      "(3216, 631, 3454, 712) linear,\n",
      "HEY HEY HEY 0\n",
      "(3485, 653, 3580, 699) no\n",
      "HEY HEY HEY 0\n",
      "(3608, 631, 4375, 720) feature—|recognition\n",
      "HEY HEY HEY 0\n",
      "(1989, 743, 2256, 811) feature\n",
      "HEY HEY HEY 0\n",
      "(2288, 743, 2653, 832) similarity\n",
      "HEY HEY HEY 0\n",
      "(681, 862, 807, 930) has\n",
      "HEY HEY HEY 0\n",
      "(839, 884, 879, 930) a\n",
      "HEY HEY HEY 0\n",
      "(907, 862, 1311, 951) smoothing\n",
      "HEY HEY HEY 0\n",
      "(1338, 872, 1725, 950) parameter\n",
      "HEY HEY HEY 0\n",
      "(1750, 872, 1824, 930) to\n",
      "HEY HEY HEY 0\n",
      "(0, 0, 5236, 2697) _\n",
      "HEY HEY HEY 0\n",
      "(1988, 862, 2107, 930) |the\n",
      "HEY HEY HEY 0\n",
      "(2137, 862, 2541, 951) smoothing\n",
      "HEY HEY HEY 0\n",
      "(2568, 872, 2956, 950) parameter\n",
      "HEY HEY HEY 0\n",
      "(2982, 884, 3113, 930) can\n",
      "HEY HEY HEY 0\n",
      "(3143, 862, 3407, 951) greatly\n",
      "HEY HEY HEY 0\n",
      "(3432, 862, 3649, 930) effect\n",
      "HEY HEY HEY 0\n",
      "(3679, 862, 3839, 930) data\n",
      "HEY HEY HEY 0\n",
      "(3935, 862, 4198, 951) |mostly\n",
      "HEY HEY HEY 0\n",
      "(4222, 862, 4401, 930) used\n",
      "HEY HEY HEY 0\n",
      "(4427, 862, 4502, 929) in\n",
      "HEY HEY HEY 0\n",
      "(4529, 872, 4894, 950) computer\n",
      "HEY HEY HEY 0\n",
      "(683, 974, 1069, 1042) determine\n",
      "HEY HEY HEY 0\n",
      "(1095, 974, 1211, 1042) the\n",
      "HEY HEY HEY 0\n",
      "(1238, 974, 1598, 1042) influence\n",
      "HEY HEY HEY 0\n",
      "(1627, 974, 1708, 1042) of\n",
      "HEY HEY HEY 0\n",
      "(1729, 974, 1905, 1042) each\n",
      "HEY HEY HEY 0\n",
      "(1989, 974, 2245, 1063) |fitting,\n",
      "HEY HEY HEY 0\n",
      "(2276, 996, 2371, 1042) no\n",
      "HEY HEY HEY 0\n",
      "(2399, 974, 2968, 1042) feature—feature\n",
      "HEY HEY HEY 0\n",
      "(2998, 974, 3364, 1063) similarity\n",
      "HEY HEY HEY 0\n",
      "(3988, 974, 4065, 984) 181\n",
      "HEY HEY HEY 0\n",
      "(681, 1085, 1018, 1166) instance,\n",
      "HEY HEY HEY 0\n",
      "(1049, 1085, 1456, 1153) translation\n",
      "HEY HEY HEY 0\n",
      "(1485, 1085, 1826, 1153) invariant\n",
      "HEY HEY HEY 0\n",
      "(41, 1181, 822, 1516) less\n",
      "HEY HEY HEY 0\n",
      "(856, 1202, 1280, 1290) susceptible\n",
      "HEY HEY HEY 0\n",
      "(1307, 1212, 1381, 1270) to\n",
      "HEY HEY HEY 0\n",
      "(1408, 1202, 1618, 1291) noisy\n",
      "HEY HEY HEY 0\n",
      "(1644, 1202, 1823, 1283) data,\n",
      "HEY HEY HEY 0\n",
      "(0, 0, 5236, 2697) _\n",
      "HEY HEY HEY 0\n",
      "(1990, 1202, 2161, 1291) |only\n",
      "HEY HEY HEY 0\n",
      "(2187, 1202, 2698, 1291) conditionally\n",
      "HEY HEY HEY 0\n",
      "(2721, 1202, 2949, 1290) p.s.d.,\n",
      "HEY HEY HEY 0\n",
      "(2980, 1212, 3402, 1290) parameters\n",
      "HEY HEY HEY 0\n",
      "(3432, 1212, 3618, 1270) must\n",
      "HEY HEY HEY 0\n",
      "(3643, 1202, 3733, 1270) be\n",
      "HEY HEY HEY 0\n",
      "(3937, 1202, 4219, 1291) generic\n",
      "HEY HEY HEY 0\n",
      "(113, 864, 170, 929) B\n",
      "HEY HEY HEY 0\n",
      "(136, 1204, 194, 1269) L\n",
      "HEY HEY HEY 0\n",
      "(136, 1550, 180, 1618) S\n",
      "HEY HEY HEY 0\n",
      "(681, 1314, 807, 1382) has\n",
      "HEY HEY HEY 0\n",
      "(840, 1336, 1037, 1382) some\n",
      "HEY HEY HEY 0\n",
      "(1069, 1314, 1491, 1403) advantages\n",
      "HEY HEY HEY 0\n",
      "(1524, 1314, 1606, 1382) of\n",
      "HEY HEY HEY 0\n",
      "(1628, 1314, 1867, 1382) neural\n",
      "HEY HEY HEY 0\n",
      "(0, 0, 5236, 2697) _\n",
      "HEY HEY HEY 0\n",
      "(1988, 1314, 2224, 1395) |tuned,\n",
      "HEY HEY HEY 0\n",
      "(2256, 1336, 2350, 1382) no\n",
      "HEY HEY HEY 0\n",
      "(2378, 1314, 2946, 1382) feature—feature\n",
      "HEY HEY HEY 0\n",
      "(2975, 1314, 3343, 1403) similarity\n",
      "HEY HEY HEY 0\n",
      "(681, 1425, 1032, 1493) networks\n",
      "HEY HEY HEY 0\n",
      "(177, 864, 230, 929) F\n",
      "HEY HEY HEY 0\n",
      "(193, 1204, 245, 1269) P\n",
      "HEY HEY HEY 0\n",
      "(49, 1550, 318, 1638) xy—Sim/\n",
      "HEY HEY HEY 0\n",
      "(682, 1555, 1050, 1633) computes\n",
      "HEY HEY HEY 0\n",
      "(1081, 1545, 1650, 1613) feature—feature\n",
      "HEY HEY HEY 0\n",
      "(1990, 1545, 2161, 1613) does\n",
      "HEY HEY HEY 0\n",
      "(2193, 1555, 2315, 1613) not\n",
      "HEY HEY HEY 0\n",
      "(2342, 1545, 2610, 1633) exploit\n",
      "HEY HEY HEY 0\n",
      "(2637, 1555, 2967, 1634) category\n",
      "HEY HEY HEY 0\n",
      "(2992, 1545, 3215, 1613) labels\n",
      "HEY HEY HEY 0\n",
      "(3245, 1545, 3354, 1613) for\n",
      "HEY HEY HEY 0\n",
      "(3386, 1545, 3751, 1634) similarity\n",
      "HEY HEY HEY 0\n",
      "(3939, 1567, 4196, 1633) sparse,\n",
      "HEY HEY HEY 0\n",
      "(4227, 1545, 4905, 1634) high—dimensional\n",
      "HEY HEY HEY 0\n",
      "(4935, 1545, 5095, 1613) data\n",
      "HEY HEY HEY 0\n",
      "(48, 1664, 343, 1732) IHOSK\n",
      "HEY HEY HEY 0\n",
      "(685, 1656, 1069, 1745) similarity,\n",
      "HEY HEY HEY 0\n",
      "(1104, 1656, 1292, 1745) good\n",
      "HEY HEY HEY 0\n",
      "(1321, 1656, 1430, 1724) for\n",
      "HEY HEY HEY 0\n",
      "(1462, 1678, 1701, 1744) sparse\n",
      "HEY HEY HEY 0\n",
      "(1727, 1656, 1927, 1745) high—\n",
      "HEY HEY HEY 0\n",
      "(1989, 1656, 2473, 1744) |computation\n",
      "HEY HEY HEY 0\n",
      "(3939, 1657, 4102, 1745) (e.g.\n",
      "HEY HEY HEY 0\n",
      "(4132, 1666, 4298, 1737) text,\n",
      "HEY HEY HEY 0\n",
      "(4331, 1678, 4510, 1745) gene\n",
      "HEY HEY HEY 0\n",
      "(4537, 1656, 4969, 1744) expression,\n",
      "HEY HEY HEY 0\n",
      "(5001, 1656, 5152, 1723) link\n",
      "HEY HEY HEY 0\n",
      "(683, 1768, 1153, 1836) dimensional\n",
      "HEY HEY HEY 0\n",
      "(1183, 1768, 1343, 1836) data\n",
      "HEY HEY HEY 0\n",
      "(3938, 1768, 4275, 1857) analysis)\n",
      "HEY HEY HEY 0\n",
      "(47, 1885, 466, 1953) Euclidean—\n",
      "HEY HEY HEY 0\n",
      "(681, 1907, 846, 1953) uses\n",
      "HEY HEY HEY 0\n",
      "(876, 1895, 1206, 1974) category\n",
      "HEY HEY HEY 0\n",
      "(1233, 1907, 1528, 1974) average\n",
      "HEY HEY HEY 0\n",
      "(1558, 1895, 1632, 1953) to\n",
      "HEY HEY HEY 0\n",
      "(1660, 1885, 1870, 1953) avord\n",
      "HEY HEY HEY 0\n",
      "(1988, 1895, 2110, 1953)  |not\n",
      "HEY HEY HEY 0\n",
      "(2141, 1885, 2433, 1974) directly\n",
      "HEY HEY HEY 0\n",
      "(2460, 1907, 2500, 1953) a\n",
      "HEY HEY HEY 0\n",
      "(2527, 1885, 2766, 1953) kernel\n",
      "HEY HEY HEY 0\n",
      "(2793, 1885, 2916, 1953) but\n",
      "HEY HEY HEY 0\n",
      "(2940, 1885, 3167, 1953) rather\n",
      "HEY HEY HEY 0\n",
      "(3195, 1907, 3283, 1953) an\n",
      "HEY HEY HEY 0\n",
      "(3312, 1885, 3515, 1953) SVM\n",
      "HEY HEY HEY 0\n",
      "(3541, 1885, 3763, 1953) based\n",
      "HEY HEY HEY 0\n",
      "(0, 0, 5236, 2697) _\n",
      "HEY HEY HEY 0\n",
      "(3937, 1885, 4219, 1974) |generic\n",
      "HEY HEY HEY 0\n",
      "(50, 1996, 256, 2064) SVM\n",
      "HEY HEY HEY 0\n",
      "(685, 1996, 983, 2085) sparsity\n",
      "HEY HEY HEY 0\n",
      "(1006, 1996, 1333, 2084) problem\n",
      "HEY HEY HEY 0\n",
      "(1989, 1996, 2358, 2077) classifier,\n",
      "HEY HEY HEY 0\n",
      "(2390, 2018, 2484, 2064) no\n",
      "HEY HEY HEY 0\n",
      "(2512, 1996, 3082, 2064) feature—feature\n",
      "HEY HEY HEY 0\n",
      "(3113, 1996, 3478, 2085) similarity\n",
      "HEY HEY HEY 0\n",
      "(41, 2092, 877, 2317) takes\n",
      "HEY HEY HEY 0\n",
      "(906, 2113, 1054, 2181) into\n",
      "HEY HEY HEY 0\n",
      "(1085, 2123, 1380, 2181) account\n",
      "HEY HEY HEY 0\n",
      "(1406, 2113, 1704, 2181) indirect\n",
      "HEY HEY HEY 0\n",
      "(1728, 2113, 1913, 2181) links\n",
      "HEY HEY HEY 0\n",
      "(1989, 2113, 2620, 2202) |computationally\n",
      "HEY HEY HEY 0\n",
      "(2645, 2113, 3032, 2201) expensive\n",
      "HEY HEY HEY 0\n",
      "(49, 2225, 310, 2293) Kernel\n",
      "HEY HEY HEY 0\n",
      "(49, 2344, 254, 2412) Class\n",
      "HEY HEY HEY 0\n",
      "(283, 2344, 626, 2433) Meaning\n",
      "HEY HEY HEY 0\n",
      "(685, 2344, 999, 2412) |smooths\n",
      "HEY HEY HEY 0\n",
      "(1030, 2354, 1242, 2412) terms\n",
      "HEY HEY HEY 0\n",
      "(1270, 2344, 1366, 2433) by\n",
      "HEY HEY HEY 0\n",
      "(1390, 2344, 1653, 2433) having\n",
      "HEY HEY HEY 0\n",
      "(1681, 2344, 1899, 2412) class—\n",
      "HEY HEY HEY 0\n",
      "(1992, 2344, 2289, 2432) |specific\n",
      "HEY HEY HEY 0\n",
      "(2315, 2354, 2388, 2412) to\n",
      "HEY HEY HEY 0\n",
      "(2416, 2354, 2580, 2425) text,\n",
      "HEY HEY HEY 0\n",
      "(2613, 2344, 2784, 2412) does\n",
      "HEY HEY HEY 0\n",
      "(2813, 2354, 2935, 2412) not\n",
      "HEY HEY HEY 0\n",
      "(2961, 2344, 3120, 2412) take\n",
      "HEY HEY HEY 0\n",
      "(3147, 2344, 3634, 2433) higher—order\n",
      "HEY HEY HEY 0\n",
      "(3935, 2344, 4197, 2412) textual\n",
      "HEY HEY HEY 0\n",
      "(4227, 2344, 4387, 2412) data\n",
      "HEY HEY HEY 0\n",
      "(681, 2455, 1033, 2544) meaning,\n",
      "HEY HEY HEY 0\n",
      "(1067, 2455, 1445, 2523) automatic\n",
      "HEY HEY HEY 0\n",
      "(1474, 2455, 1739, 2523) feature\n",
      "HEY HEY HEY 0\n",
      "(1992, 2455, 2417, 2523) similarities\n",
      "HEY HEY HEY 0\n",
      "(2444, 2455, 2595, 2523) into\n",
      "HEY HEY HEY 0\n",
      "(2623, 2465, 2939, 2523) account.\n",
      "HEY HEY HEY 0\n",
      "(682, 2567, 1087, 2656) weighting,\n",
      "HEY HEY HEY 0\n",
      "(1119, 2567, 1261, 2635) low\n",
      "HEY HEY HEY 0\n",
      "(1291, 2567, 1724, 2656) complexity\n",
      "HEY HEY HEY 0\n",
      "(32, 27, 5204, 2670)  \n",
      "HEY HEY HEY 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "FileTextBuffer = \"\"\n",
    "FileTextBuffer += \"<document>\\n\"\n",
    "\n",
    "pagecounter  = 1\n",
    "for page in filepageImages[2:3]:\n",
    "    print(pagecounter)\n",
    "    thisPageText = \"\"\n",
    "    thisPageText += \"<page\" +str(pagecounter)+\">\\n\"\n",
    "    \n",
    "    with PyTessBaseAPI(path = pytestapi_path) as api:\n",
    "        api.SetImage(page)\n",
    "        api.Recognize()\n",
    "        PILimage = page.copy()\n",
    "        NUMPYimage = np.array(page, dtype='int16')\n",
    "        \n",
    "        ## Preprosessing for background detection --START\n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.WORD\n",
    "        # Word by word iterator \n",
    "        for r in iterate_level(ri, level):\n",
    "            if r:\n",
    "                bbox = r.BoundingBox(level)\n",
    "                #print(bbox)\n",
    "                if bbox: ## Now black (-1) 'em out\n",
    "                    # Word_BBoxes.append(bbox)\n",
    "                    # print(bbox)\n",
    "                    #print(bbox)\n",
    "                    #print(NUMPYimage.shape)\n",
    "                    NUMPYimage[bbox[1]:bbox[3], bbox[0]:bbox[2], :] = -1\n",
    "        ## Preprosessing for background detection --END\n",
    "        \n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.BLOCK # Block based Values \n",
    "\n",
    "        # Table is detectable ( we can get the verticle and horizental Lins )\n",
    "        for r in iterate_level(ri, level):\n",
    "            if r:\n",
    "                block_type = r.BlockType() # Type of that specific block\n",
    "                try:\n",
    "                    tmp = r.GetUTF8Text(level)\n",
    "\n",
    "                    #print(r.ParagraphInfo())\n",
    "\n",
    "                    #print(block_type, tmp)\n",
    "                    if (block_type is PT.TABLE) or  (block_type == PT.FLOWING_IMAGE):\n",
    "                        print(\"yes\")\n",
    "                        table_image = r.GetImage(level, 30, PILimage)\n",
    "                        if table_image:\n",
    "                            text_rows = get_table_row_tags(table_image[0])\n",
    "                            #print(text_rows)\n",
    "                            if(text_rows):\n",
    "                                thisPageText += text_rows\n",
    "                    elif((block_type != PT.UNKNOWN) and (tmp.rstrip() != \"\")):\n",
    "                        ###  Backgrpound Color algo -START Params (bbox, numBIN, NumpyImage)\n",
    "                        rgb_result = line_bg_detection(r.BoundingBox(level), 20, NUMPYimage)\n",
    "                        ###  Backgrpound Color algo -END\n",
    "                        if (rgb_result):\n",
    "                            thisPageText += \"<text font_bg = '\" + rgb_result[0] + \",\" + rgb_result[1] + \",\" + rgb_result[2] +\"'>\\n\" + r.GetUTF8Text(level) + \"</text>\\n\"\n",
    "                        else:\n",
    "                            thisPageText += \"<text>\\n\" + r.GetUTF8Text(level) + \"</text>\\n\"\n",
    "                except:\n",
    "                    pass\n",
    "    FileTextBuffer += thisPageText + \"</page\" +str(pagecounter)+\">\\n\"\n",
    "    pagecounter += 1\n",
    "\n",
    "FileTextBuffer += \"</document>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<document>\n",
      "<page1>\n",
      "<text>\n",
      "— _ We embed the task of identifying bias in the learning phase and iteratively learns from a refined training\n",
      "data whose potential outliers have been re—labeled.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "—— _ Finally, we conduct several experiments to show the effectiveness of our algorithm on several real datasets.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "The rest of this paper is organized as follows: section 2 provides a background and related work on kernels. Sections\n",
      "3.1 to 3.4 details the proposed semantic kernel while sections 3.4 — 3.6 outlines techniques incorporated to deal with\n",
      "bias in the data. We provide detailed experimental work and analysis in section 4 and conclude the discussion in this\n",
      "paper in section 5.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      ". Problem setup and background\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "In this section, we define the problem of classification in the presence of label noise. In traditional supervised\n",
      "classification, a learner is first trained on a training set whose labels are known and is then used to classify an unseen\n",
      "testing set about which it has no prior knowledge. The classifier would determine patterns, learn weights, etc. to\n",
      "identify a typical example of a class from the training label and would then attempt to classify the test data to the\n",
      "class whose pattern is exhibited.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "2.1. Supervised learning\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "Let X be a data matrix having N instances (rows) and p attributes (columns). For the sake of clarity, we will assume\n",
      "the dataset to be a document by word matrix whose rows are documents and whose columns are words and each X;;\n",
      "represents the occurrence of the word j in document i. Each instance vector, denoted as x; = [xil, Xi2» Xigs ***> xip] in\n",
      "a p—dimensional space, has an associated category label y;=k, ke{1l,...,C} where C is the number of possible\n",
      "categories. The vector yy,; contains the categories of all instances. The training data, T, can then be represented as a\n",
      "set of instances x; paired with its label y;, where the training set contains N such examples, given by\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "(1) T = URMi{(xy)}\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "Let n be the set of hypotheses using which the class of instances can be determined. We define hex as a hypothesis\n",
      "that makes a prediction for an instance x; as h(x;) = k, ke{1,...,C} and the learning algorithm then tries to find /\n",
      "that best estimates y. This is done by finding the parameters defining /A ex that would make it equal, or closest, to y.\n",
      "In practice, since we know the correct label y; Vie{1,...,N} for the training data, we can estimate the best hex. One\n",
      "way of doing this is to express the probability distribution over the possible labels given the input test vector x and\n",
      "the training set T, denoted by p(y|x,T,h) where y is the output category of x. It is clear from our notation that the\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "class label is conditional on the input vector x, the training dataset T and the chosen model /. Given a probabilistic\n",
      "output, we can now compute our \"best guess\" to the true label as\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "(2) h(x) = argmax{—,p(y = k|x,T, h)\n",
      "which corresponds to the most probable class label also known as the Maximum Aposteriori (MAP) estimate.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "The problem of supervised learning can now be expressed in terms of learning the model, /, which best estimates\n",
      "the original label y; in the set of training data or the one which makes the least number of empirical error. The\n",
      "empirical error is defined as the proportion of training instances where the predicted output label, Ah(x;), do not agree\n",
      "with the training label, y;. The empirical error given by the hypothesis / given the training data T is\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "where I is an indicator function.\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "2.2. Support Vector Machines\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "Support Vector Machines (SVM) was developed by Cortes & Vapnik (Cortes & Vapnik, 1995) for the binary\n",
      "classification task and were first applied to the task of document categorization by (Joachims, 1998). In SVM, we are\n",
      "primarily searching for the optimal separating hyperplane between the two classes. This is done by maximizing the\n",
      "margin between the closest points, 1.e., the points lying closest to the boundary. These points are known as support\n",
      "vectors and are used to find the optimal separating hyperplane as shown in Figure 1. Mathematically speaking, the\n",
      "\n",
      "</text>\n",
      "<text>\n",
      "equation for the separating hyperplane is given by\n",
      "\n",
      "</text>\n",
      "</page1>\n",
      "</document>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(FileTextBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output-DOCT_new.xml\", 'w+',encoding=\"utf-8\") as f:\n",
    "    f.write(FileTextBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "FileTextBuffer = \"\"\n",
    "FileTextBuffer += \"<document>\\n\"\n",
    "\n",
    "pagecounter  = 1\n",
    "for page in filepageImages:\n",
    "    print(pagecounter)\n",
    "    thisPageText = \"\"\n",
    "    thisPageText += \"<page\" +str(pagecounter)+\">\\n\"\n",
    "    \n",
    "    with PyTessBaseAPI(path = pytestapi_path) as api:\n",
    "        api.SetImage(page)\n",
    "        api.Recognize()\n",
    "        PILimage = page.copy()\n",
    "        NUMPYimage = np.array(page, dtype='int16')\n",
    "        \n",
    "        ## Preprosessing for background detection --START\n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.WORD\n",
    "        # Word by word iterator \n",
    "        for r in iterate_level(ri, level):\n",
    "            if r:\n",
    "                bbox = r.BoundingBox(level)\n",
    "                #print(bbox)\n",
    "                if bbox: ## Now black (-1) 'em out\n",
    "                    # Word_BBoxes.append(bbox)\n",
    "                    # print(bbox)\n",
    "                    #print(bbox)\n",
    "                    #print(NUMPYimage.shape)\n",
    "                    NUMPYimage[bbox[1]:bbox[3], bbox[0]:bbox[2], :] = -1\n",
    "        ## Preprosessing for background detection --END\n",
    "        \n",
    "        ri = api.GetIterator()\n",
    "        level = RIL.BLOCK # Block based Values \n",
    "\n",
    "        # Table is detectable ( we can get the verticle and horizental Lins )\n",
    "        for r in iterate_level(ri, level):\n",
    "            if r:\n",
    "                block_type = r.BlockType() # Type of that specific blocl\n",
    "                tmp = r.GetUTF8Text(level)\n",
    "\n",
    "                #print(r.ParagraphInfo())\n",
    "                \n",
    "                #print(block_type, tmp)\n",
    "                if (block_type is PT.TABLE) or  (block_type == PT.FLOWING_IMAGE):\n",
    "                    #print(\"yes\")\n",
    "                    # table_image = r.GetImage(level, 5, PILimage)\n",
    "                    \n",
    "                    # if table_image:\n",
    "                    #    text_rows = get_table_row_tags(table_image[0])\n",
    "                    #    #print(text_rows)\n",
    "                    #   if(text_rows):\n",
    "                    #        thisPageText += text_rows\n",
    "                    tmp_text\n",
    "                elif((block_type != PT.UNKNOWN) and (tmp.rstrip() != \"\")):\n",
    "                    ###  Backgrpound Color algo -START Params (bbox, numBIN, NumpyImage)\n",
    "                    rgb_result = line_bg_detection(r.BoundingBox(level), 20, NUMPYimage)\n",
    "                    ###  Backgrpound Color algo -END\n",
    "                    if (rgb_result):\n",
    "                        thisPageText += \"<text font_bg = '\" + rgb_result[0] + \",\" + rgb_result[1] + \",\" + rgb_result[2] +\"'>\\n\" + r.GetUTF8Text(level) + \"</text>\\n\"\n",
    "                    else:\n",
    "                        thisPageText += \"<text>\\n\" + r.GetUTF8Text(level) + \"</text>\\n\"\n",
    "    FileTextBuffer += thisPageText + \"</page\" +str(pagecounter)+\">\\n\"\n",
    "    pagecounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
